{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yeah': 52, 'xxx': 44, 'mommy': 34, 'V': 28, 'is': 19, 'two': 17, 'tape': 15, 'this': 15, 'Baba': 15, 'laugh': 14, 'what': 14, 'it': 13, 'baby': 13, 'bird': 13, 'old': 12, 's': 11, 'up': 10, 'new': 9, 'birdie': 9, 'player': 8, 'red': 8, 'eat': 8, 'book': 8, 'big': 7, 'duck': 7, 'Tot': 7, 'boat': 7, 'and': 6, 'laughs': 6, 'green': 6, 'upstairs': 6, 'a': 5, 'one': 5, 'in': 5, 'egg': 5, 'Time': 5, 'that': 4, 'here': 4, 'New': 4, 'Investigator': 4, 'books': 4, 'heavy': 4, 'babies': 4, '0': 3, 'nose': 3, 'on': 3, 'boom': 3, 'or': 3, 'boots': 3, 'socks': 3, 'Sara': 3, 'plane': 3, 'three': 3, 'hair': 3, 'o': 2, 'f': 2, 'birds': 2, 'poems': 2, 'eyes': 2, 'get': 2, 'the': 2, 'off': 2, 'daddy': 2, 'h': 2, 'light': 2, 'poem': 2, 'inside': 2, 'tv': 2, 'no': 2, 'eggs': 2, 'she': 2, 'an': 2, 'hi': 2, 'mine': 2, 'orange': 2, 'boon': 2, 'Nana': 2, 'tikteat': 2, 'trick': 2, 'treat': 2, 'Carleton': 2, 'fly': 2, 'CHI': 2, 'these': 2, 'at': 2, 't': 2, 'I': 2, 'blue': 2, 'head': 2, 'c': 2, 'home': 2, 'tops': 2, 'nap': 2, 'house': 2, 'oh': 2, 'Riding': 2, 'players': 1, 'have': 1, 'rafi': 1, 'raffi': 1, 'Ernie': 1, 'Laughs': 1, 'hug': 1, 'stroller': 1, 'Laugh': 1, 'run': 1, 'away': 1, 'Nanny': 1, 'juice': 1, 'black': 1, 'right': 1, 'trying': 1, 'to': 1, 'go': 1, 'through': 1, 'bone': 1, 'MOT': 1, 'inv': 1, 'let': 1, 'Yawns': 1, 'audibly': 1, 'yellow': 1, 'out': 1, 'duckie': 1, 'What': 1, 'doing': 1, 'imitating': 1, 'elephant': 1, 'trumpeting': 1, 'noise': 1, 'hey': 1, 'Squeak': 1, 'noises': 1, 'eye': 1, 'yyy': 1, 'Squeaky': 1, 'pu': 1, 'm': 1, 'pkin': 1, 'name': 1, 'of': 1, 'their': 1, 'sitter': 1, 'sit': 1, 'down': 1, 'phone': 1, 'has': 1, 'four': 1, 'year': 1, 'friend': 1, 'named': 1, 'Daddy': 1, 'battries': 1, 'hail': 1, 'sail': 1, 'wha': 1, 'i': 1, 'again': 1, 'think': 1, 'saying': 1, 'but': 1, 'pronounced': 1, 'strangely': 1, 'too': 1, 'bee': 1, 'sighs': 1, 'oof': 1, 'jay': 1, 'ish': 1, 'Robin': 1, 'dot': 1, 'p': 1, 'l': 1, 'ease': 1, 'help': 1, 'b': 1, 'shoe': 1, 'tree': 1, 'diapies': 1, 'diapers': 1, 'boot': 1, 'Tape': 1, 'turned': 1, 'played': 1, 'back': 1, 'for': 1, 'scissors': 1, 'clock': 1, 'wolf': 1, 'um': 1, 'aba': 1, 'Saab': 1, 'Mazda': 1, 'don': 1, 'know': 1, 'he': 1, 'riding': 1, 'ow': 1, 'woof': 1})\n"
     ]
    }
   ],
   "source": [
    "#to read a file, and count all the words in all the lines in the file\n",
    "import re\n",
    "from collections import Counter\n",
    "fpath=\"Downloads/Valian/01a.cha\"\n",
    "\n",
    "fopen=open(fpath)\n",
    "#content=fopen.read()\n",
    "all_words=[]\n",
    "#for file_name in os.listdir()\n",
    "for f in fopen:\n",
    "    if f.startswith(\"*CHI\"):\n",
    "        #print(f)\n",
    "        words=re.findall(\"\\w+\",f)\n",
    "        #print(words[1:])\n",
    "        all_words.extend(words[1:])\n",
    "        #print(\"---\")\n",
    "fopen.close()\n",
    "\n",
    "our_counter=Counter(all_words)\n",
    "print(our_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloads/Valian/01a.cha\n",
      "Downloads/Valian/01b.cha\n",
      "Downloads/Valian/02a.cha\n",
      "Downloads/Valian/02b.cha\n",
      "Downloads/Valian/03a.cha\n",
      "Downloads/Valian/03b.cha\n",
      "Downloads/Valian/04a.cha\n",
      "Downloads/Valian/04b.cha\n",
      "Downloads/Valian/04c.cha\n",
      "Downloads/Valian/05a.cha\n",
      "Downloads/Valian/06a.cha\n",
      "Downloads/Valian/06b.cha\n",
      "Downloads/Valian/07a.cha\n",
      "Downloads/Valian/08a.cha\n",
      "Downloads/Valian/08b.cha\n",
      "Downloads/Valian/09a.cha\n",
      "Downloads/Valian/09b.cha\n",
      "Downloads/Valian/09c.cha\n",
      "Downloads/Valian/0metadata.cdc\n",
      "Downloads/Valian/10a.cha\n",
      "Downloads/Valian/10b.cha\n",
      "Downloads/Valian/10c.cha\n",
      "Downloads/Valian/11a.cha\n",
      "Downloads/Valian/11b.cha\n",
      "Downloads/Valian/12a.cha\n",
      "Downloads/Valian/12b.cha\n",
      "Downloads/Valian/13a.cha\n",
      "Downloads/Valian/13b.cha\n",
      "Downloads/Valian/14a.cha\n",
      "Downloads/Valian/14b.cha\n",
      "Downloads/Valian/15a.cha\n",
      "Downloads/Valian/15b.cha\n",
      "Downloads/Valian/16a.cha\n",
      "Downloads/Valian/16b.cha\n",
      "Downloads/Valian/17a.cha\n",
      "Downloads/Valian/17b.cha\n",
      "Downloads/Valian/18a.cha\n",
      "Downloads/Valian/19a.cha\n",
      "Downloads/Valian/19b.cha\n",
      "Downloads/Valian/20a.cha\n",
      "Downloads/Valian/20b.cha\n",
      "Downloads/Valian/21a.cha\n",
      "Downloads/Valian/21b.cha\n",
      "Downloads/Valian/21c.cha\n"
     ]
    }
   ],
   "source": [
    "#if you are reading all files in a directory\n",
    "import os\n",
    "our_dir=\"Downloads/Valian\"\n",
    "for fname in os.listdir(our_dir):\n",
    "    cur_fpath=os.path.join(our_dir,fname)\n",
    "    print(cur_fpath)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_words(file_path):\n",
    "    fopen=open(file_path)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'common': 2, 'core': 2, 'state': 2, 'standards': 2, 'one': 1, 'of': 1, 'our': 1, 'goals': 1, 'is': 1, 'to': 1, 'do': 1, 'the': 1, 'which': 1, 'also': 1, 'has': 1, 'here': 1})\n"
     ]
    }
   ],
   "source": [
    "sentence=\"one of our goals is to do the common core state standards which also has common core state standards here\"\n",
    "words=sentence.split()\n",
    "our_counter=Counter(words)\n",
    "print(our_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('one', 'of'), ('of', 'our'), ('our', 'goals'), ('goals', 'is'), ('is', 'to'), ('to', 'do'), ('do', 'the'), ('the', 'common'), ('common', 'core'), ('core', 'state'), ('state', 'standards'), ('standards', 'which'), ('which', 'also'), ('also', 'has'), ('has', 'common'), ('common', 'core'), ('core', 'state'), ('state', 'standards'), ('standards', 'here')]\n"
     ]
    }
   ],
   "source": [
    "bigrams=[(words[i],words[i+1]) for i in range(len(words)-1)]\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('one', 'of', 'our'), ('of', 'our', 'goals'), ('our', 'goals', 'is'), ('goals', 'is', 'to'), ('is', 'to', 'do'), ('to', 'do', 'the'), ('do', 'the', 'common'), ('the', 'common', 'core'), ('common', 'core', 'state'), ('core', 'state', 'standards'), ('state', 'standards', 'which'), ('standards', 'which', 'also'), ('which', 'also', 'has'), ('also', 'has', 'common'), ('has', 'common', 'core'), ('common', 'core', 'state'), ('core', 'state', 'standards'), ('state', 'standards', 'here')]\n"
     ]
    }
   ],
   "source": [
    "trigrams=[(words[i],words[i+1],words[i+2]) for i in range(len(words)-2)]\n",
    "print(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('one', 'of', 'our', 'goals'), ('of', 'our', 'goals', 'is'), ('our', 'goals', 'is', 'to'), ('goals', 'is', 'to', 'do'), ('is', 'to', 'do', 'the'), ('to', 'do', 'the', 'common'), ('do', 'the', 'common', 'core'), ('the', 'common', 'core', 'state'), ('common', 'core', 'state', 'standards'), ('core', 'state', 'standards', 'which'), ('state', 'standards', 'which', 'also'), ('standards', 'which', 'also', 'has'), ('which', 'also', 'has', 'common'), ('also', 'has', 'common', 'core'), ('has', 'common', 'core', 'state'), ('common', 'core', 'state', 'standards'), ('core', 'state', 'standards', 'here')]\n"
     ]
    }
   ],
   "source": [
    "fourgrams=[(words[i],words[i+1],words[i+2],words[i+3]) for i in range(len(words)-3)]\n",
    "print(fourgrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('common', 'core', 'state', 'standards'): 2, ('one', 'of', 'our', 'goals'): 1, ('of', 'our', 'goals', 'is'): 1, ('our', 'goals', 'is', 'to'): 1, ('goals', 'is', 'to', 'do'): 1, ('is', 'to', 'do', 'the'): 1, ('to', 'do', 'the', 'common'): 1, ('do', 'the', 'common', 'core'): 1, ('the', 'common', 'core', 'state'): 1, ('core', 'state', 'standards', 'which'): 1, ('state', 'standards', 'which', 'also'): 1, ('standards', 'which', 'also', 'has'): 1, ('which', 'also', 'has', 'common'): 1, ('also', 'has', 'common', 'core'): 1, ('has', 'common', 'core', 'state'): 1, ('core', 'state', 'standards', 'here'): 1})\n"
     ]
    }
   ],
   "source": [
    "fourgram_counter=Counter(fourgrams)\n",
    "print(fourgram_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'of', 'our', 'goals', 'is', 'to', 'do', 'the', 'common', 'core', 'state', 'standards', 'which', 'also', 'has', 'common', 'core', 'state', 'standards', 'here', ('one', 'of'), ('of', 'our'), ('our', 'goals'), ('goals', 'is'), ('is', 'to'), ('to', 'do'), ('do', 'the'), ('the', 'common'), ('common', 'core'), ('core', 'state'), ('state', 'standards'), ('standards', 'which'), ('which', 'also'), ('also', 'has'), ('has', 'common'), ('common', 'core'), ('core', 'state'), ('state', 'standards'), ('standards', 'here'), ('one', 'of', 'our'), ('of', 'our', 'goals'), ('our', 'goals', 'is'), ('goals', 'is', 'to'), ('is', 'to', 'do'), ('to', 'do', 'the'), ('do', 'the', 'common'), ('the', 'common', 'core'), ('common', 'core', 'state'), ('core', 'state', 'standards'), ('state', 'standards', 'which'), ('standards', 'which', 'also'), ('which', 'also', 'has'), ('also', 'has', 'common'), ('has', 'common', 'core'), ('common', 'core', 'state'), ('core', 'state', 'standards'), ('state', 'standards', 'here'), ('one', 'of', 'our', 'goals'), ('of', 'our', 'goals', 'is'), ('our', 'goals', 'is', 'to'), ('goals', 'is', 'to', 'do'), ('is', 'to', 'do', 'the'), ('to', 'do', 'the', 'common'), ('do', 'the', 'common', 'core'), ('the', 'common', 'core', 'state'), ('common', 'core', 'state', 'standards'), ('core', 'state', 'standards', 'which'), ('state', 'standards', 'which', 'also'), ('standards', 'which', 'also', 'has'), ('which', 'also', 'has', 'common'), ('also', 'has', 'common', 'core'), ('has', 'common', 'core', 'state'), ('common', 'core', 'state', 'standards'), ('core', 'state', 'standards', 'here')]\n"
     ]
    }
   ],
   "source": [
    "ngrams=words+bigrams+trigrams+fourgrams\n",
    "print(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'common': 2, 'core': 2, 'state': 2, 'standards': 2, ('common', 'core'): 2, ('core', 'state'): 2, ('state', 'standards'): 2, ('common', 'core', 'state'): 2, ('core', 'state', 'standards'): 2, ('common', 'core', 'state', 'standards'): 2, 'one': 1, 'of': 1, 'our': 1, 'goals': 1, 'is': 1, 'to': 1, 'do': 1, 'the': 1, 'which': 1, 'also': 1, 'has': 1, 'here': 1, ('one', 'of'): 1, ('of', 'our'): 1, ('our', 'goals'): 1, ('goals', 'is'): 1, ('is', 'to'): 1, ('to', 'do'): 1, ('do', 'the'): 1, ('the', 'common'): 1, ('standards', 'which'): 1, ('which', 'also'): 1, ('also', 'has'): 1, ('has', 'common'): 1, ('standards', 'here'): 1, ('one', 'of', 'our'): 1, ('of', 'our', 'goals'): 1, ('our', 'goals', 'is'): 1, ('goals', 'is', 'to'): 1, ('is', 'to', 'do'): 1, ('to', 'do', 'the'): 1, ('do', 'the', 'common'): 1, ('the', 'common', 'core'): 1, ('state', 'standards', 'which'): 1, ('standards', 'which', 'also'): 1, ('which', 'also', 'has'): 1, ('also', 'has', 'common'): 1, ('has', 'common', 'core'): 1, ('state', 'standards', 'here'): 1, ('one', 'of', 'our', 'goals'): 1, ('of', 'our', 'goals', 'is'): 1, ('our', 'goals', 'is', 'to'): 1, ('goals', 'is', 'to', 'do'): 1, ('is', 'to', 'do', 'the'): 1, ('to', 'do', 'the', 'common'): 1, ('do', 'the', 'common', 'core'): 1, ('the', 'common', 'core', 'state'): 1, ('core', 'state', 'standards', 'which'): 1, ('state', 'standards', 'which', 'also'): 1, ('standards', 'which', 'also', 'has'): 1, ('which', 'also', 'has', 'common'): 1, ('also', 'has', 'common', 'core'): 1, ('has', 'common', 'core', 'state'): 1, ('core', 'state', 'standards', 'here'): 1})\n"
     ]
    }
   ],
   "source": [
    "ngram_counter=Counter(ngrams)\n",
    "print(ngram_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one of', 'of our', 'our goals', 'goals is', 'is to', 'to do', 'do the', 'the common', 'common core', 'core state', 'state standards', 'standards which', 'which also', 'also has', 'has common', 'common core', 'core state', 'state standards', 'standards here']\n"
     ]
    }
   ],
   "source": [
    "bigrams_str=[f\"{words[i]} {words[i+1]}\" for i in range(len(words)-1)]\n",
    "print(bigrams_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('one', 'CD'), ('of', 'IN'), ('our', 'PRP$'), ('goals', 'NNS'), ('is', 'VBZ'), ('to', 'TO'), ('do', 'VB'), ('the', 'DT'), ('common', 'JJ'), ('core', 'NN'), ('state', 'NN'), ('standards', 'NNS'), ('which', 'WDT'), ('also', 'RB'), ('has', 'VBZ'), ('common', 'JJ'), ('core', 'NN'), ('state', 'NN'), ('standards', 'NNS'), ('here', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "tags=nltk.pos_tag(words)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one CD\n",
      "of IN\n",
      "our PRP$\n",
      "goals NNS\n",
      "is VBZ\n",
      "to TO\n",
      "do VB\n",
      "the DT\n",
      "common JJ\n",
      "core NN\n",
      "state NN\n",
      "standards NNS\n",
      "which WDT\n",
      "also RB\n",
      "has VBZ\n",
      "common JJ\n",
      "core NN\n",
      "state NN\n",
      "standards NNS\n",
      "here RB\n"
     ]
    }
   ],
   "source": [
    "for word,tag in tags:\n",
    "    print(word,tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word=\"!\"\n",
    "word in string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"vin\" in \"invincible\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"v\" in \"aversion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"v\" in frozenset(\"aversion\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
